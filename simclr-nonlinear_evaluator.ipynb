{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-04-26T11:29:42.324526Z","iopub.status.busy":"2023-04-26T11:29:42.324055Z","iopub.status.idle":"2023-04-26T11:29:57.293025Z","shell.execute_reply":"2023-04-26T11:29:57.291687Z","shell.execute_reply.started":"2023-04-26T11:29:42.324475Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting imutils\n","  Downloading imutils-0.5.4.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hBuilding wheels for collected packages: imutils\n","  Building wheel for imutils (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for imutils: filename=imutils-0.5.4-py3-none-any.whl size=25861 sha256=2c2ef47edc891ba3e2343f91ae88098abddc2d7381e1c1f9ea793e27ffd768d6\n","  Stored in directory: /root/.cache/pip/wheels/35/e4/69/cb99d996d14a2971b79b990d68b05a17d58ce530ff96090dfc\n","Successfully built imutils\n","Installing collected packages: imutils\n","Successfully installed imutils-0.5.4\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install imutils"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-04-26T11:29:57.296255Z","iopub.status.busy":"2023-04-26T11:29:57.295829Z","iopub.status.idle":"2023-04-26T11:29:57.305023Z","shell.execute_reply":"2023-04-26T11:29:57.303855Z","shell.execute_reply.started":"2023-04-26T11:29:57.296205Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.layers import Layer\n","from tensorflow.keras.layers import Dense, Input, Lambda, Input, Conv2D, MaxPooling2D, Activation, GlobalAveragePooling2D\n","import tensorflow as tf \n","import tensorflow.keras as keras "]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-04-26T11:29:57.307196Z","iopub.status.busy":"2023-04-26T11:29:57.306636Z","iopub.status.idle":"2023-04-26T11:29:57.330169Z","shell.execute_reply":"2023-04-26T11:29:57.329228Z","shell.execute_reply.started":"2023-04-26T11:29:57.307157Z"},"trusted":true},"outputs":[],"source":["from imutils import paths \n","\n","train_image_files = list(paths.list_images('train'))\n","test_image_files = list(paths.list_images('test'))\n","val_image_files = list(paths.list_images('val'))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from tensorflow import keras \n","import tensorflow as tf \n","\n","# Image preprocessing utils\n","def parse_images(image_path): \n","    \"\"\"\n","        this function, will read the image from the directory, and resize it to the 224 image shape, which is predefined \n","        image shape of Resnet pretrained model.\n","        Params:\n","            image_path(type: str): image filepath in the directory.\n","        Return(type: tf.Image)\n","            returns the preprocessed image.\n","    \"\"\"\n","    image_string = tf.io.read_file(image_path)\n","    image = tf.image.decode_jpeg(image_string, channels=3)\n","    image = tf.image.convert_image_dtype(image, tf.float32)\n","    image = tf.image.resize(image, size=[224, 224])\n","\n","    return image\n","\n","def create_tensorflow_dataset(data, batch_size):\n","    \"\"\"\n","        this function, will create the tensorflow dataset from the images.\n","        Params:\n","            data(type: List): list of data, in our case list contains the file path.\n","            batch_size(type: Int): batch size for the generator.\n","        Return(type: tf.data.Dataset)\n","            returns tensorflow dataset object.\n","    \"\"\"\n","    tensorflow_data = tf.data.Dataset.from_tensor_slices(data)\n","    tensorflow_data = (\n","    tensorflow_data\n","        .map(parse_images, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n","        .shuffle(1024)\n","        .batch(batch_size, drop_remainder=True)\n","        .prefetch(tf.data.experimental.AUTOTUNE)\n","    )\n","    return tensorflow_data        "]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-04-26T11:39:19.019060Z","iopub.status.busy":"2023-04-26T11:39:19.018140Z","iopub.status.idle":"2023-04-26T11:39:19.025425Z","shell.execute_reply":"2023-04-26T11:39:19.024063Z","shell.execute_reply.started":"2023-04-26T11:39:19.019003Z"},"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-04-26T11:39:40.848781Z","iopub.status.busy":"2023-04-26T11:39:40.848103Z","iopub.status.idle":"2023-04-26T11:39:40.860516Z","shell.execute_reply":"2023-04-26T11:39:40.859367Z","shell.execute_reply.started":"2023-04-26T11:39:40.848742Z"},"trusted":true},"outputs":[],"source":["import cv2 \n","import numpy as np \n","import matplotlib.pyplot as plt \n","\n","def save_loss_plot(fpath, history): \n","    with plt.xkcd():\n","        plt.plot(history.history[\"loss\"], label=\"train_loss\")\n","        plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n","\n","        plt.title(\"Training Loss and val loss\")\n","        plt.xlabel(\"Epoch #\")\n","        plt.ylabel(\"Loss\")\n","        plt.legend(loc=\"lower left\")\n","    plt.savefig(fpath)\n","    plt.close()\n","    \n","\n","def save_acc_plot(fpath, history): \n","    with plt.xkcd():\n","        plt.plot(history.history[\"accuracy\"], label=\"train_acc\")\n","        plt.plot(history.history[\"val_accuracy\"], label=\"val_acc\")\n","        plt.title(\"Training and val Accuracy\")\n","        plt.xlabel(\"Epoch #\")\n","        plt.ylabel(\"Accuracy\")\n","        plt.legend(loc=\"lower left\")\n","    plt.savefig(fpath)\n","    plt.close()\n","\n","    \n","def create_dataset(images_files): \n","    X = []\n","    y = []\n","    for image_file in images_files:\n","        try: \n","            img = cv2.imread(image_file)\n","            img = cv2.resize(img, (224, 224))\n","            img = img / 255.0 \n","\n","            label = image_file.split(\"/\")[1].split(\"_\")[0]\n","\n","            X.append(img)\n","            y.append(label)\n","        \n","        except Exception as error:\n","            return error\n","    \n","    return np.array(X), np.array(y)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-04-26T11:31:20.508902Z","iopub.status.busy":"2023-04-26T11:31:20.508468Z","iopub.status.idle":"2023-04-26T11:31:37.591024Z","shell.execute_reply":"2023-04-26T11:31:37.588982Z","shell.execute_reply.started":"2023-04-26T11:31:20.508863Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(2700, 224, 224, 3)"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["train_X, train_y = create_dataset(train_image_files)\n","train_X.shape"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-04-26T11:31:37.594089Z","iopub.status.busy":"2023-04-26T11:31:37.593709Z","iopub.status.idle":"2023-04-26T11:31:37.601804Z","shell.execute_reply":"2023-04-26T11:31:37.600764Z","shell.execute_reply.started":"2023-04-26T11:31:37.594050Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array(['airplane', 'car', 'elephant', 'lion', 'mouse', 'tiger cub'],\n","      dtype='<U9')"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["np.unique(train_y)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-04-26T11:31:37.604009Z","iopub.status.busy":"2023-04-26T11:31:37.603362Z","iopub.status.idle":"2023-04-26T11:31:38.972225Z","shell.execute_reply":"2023-04-26T11:31:38.971275Z","shell.execute_reply.started":"2023-04-26T11:31:37.603969Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(292, 224, 224, 3)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["val_X, val_y = create_dataset(val_image_files)\n","val_X.shape"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-04-26T11:31:38.975454Z","iopub.status.busy":"2023-04-26T11:31:38.974615Z","iopub.status.idle":"2023-04-26T11:31:40.358609Z","shell.execute_reply":"2023-04-26T11:31:40.357580Z","shell.execute_reply.started":"2023-04-26T11:31:38.975413Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(300, 224, 224, 3)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["test_X, test_y = create_dataset(test_image_files)\n","test_X.shape"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-04-26T11:31:40.360477Z","iopub.status.busy":"2023-04-26T11:31:40.360026Z","iopub.status.idle":"2023-04-26T11:31:40.369219Z","shell.execute_reply":"2023-04-26T11:31:40.368153Z","shell.execute_reply.started":"2023-04-26T11:31:40.360439Z"},"trusted":true},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder\n","\n","label_encoder = LabelEncoder()\n","train_y = label_encoder.fit_transform(train_y)\n","val_y = label_encoder.transform(val_y)\n","test_y = label_encoder.transform(test_y)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-04-26T11:31:40.371529Z","iopub.status.busy":"2023-04-26T11:31:40.370593Z","iopub.status.idle":"2023-04-26T11:31:53.087531Z","shell.execute_reply":"2023-04-26T11:31:53.086440Z","shell.execute_reply.started":"2023-04-26T11:31:40.371491Z"},"trusted":true},"outputs":[],"source":["import tensorflow.keras as keras \n","from tensorflow import keras \n","\n","base_encoder_model = keras.models.load_model(\"simclr_model_1\")\n","\n","class ClassificationHed(keras.models.Model): \n","    def __init__(self, out_dims, activation_type): \n","        super(ClassificationHed, self).__init__()\n","        self.out_dims = out_dims \n","        self.activation_type = activation_type\n","        \n","        self.out_layer = keras.layers.Dense(self.out_dims, activation=self.activation_type)\n","    \n","    def call(self, tensor): \n","        x = self.out_layer(tensor)\n","        return x \n"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-04-26T11:31:53.090192Z","iopub.status.busy":"2023-04-26T11:31:53.089818Z","iopub.status.idle":"2023-04-26T11:31:53.690234Z","shell.execute_reply":"2023-04-26T11:31:53.689145Z","shell.execute_reply.started":"2023-04-26T11:31:53.090155Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," model_3 (Functional)        (None, 7, 7, 2048)        23587712  \n","                                                                 \n"," global_average_pooling2d_3   (None, 2048)             0         \n"," (GlobalAveragePooling2D)                                        \n","                                                                 \n"," classification_hed (Classif  (None, 6)                12294     \n"," icationHed)                                                     \n","                                                                 \n","=================================================================\n","Total params: 23,600,006\n","Trainable params: 12,294\n","Non-trainable params: 23,587,712\n","_________________________________________________________________\n"]}],"source":["encoder_non_linearity_model = keras.models.Sequential([\n","    base_encoder_model.layers[0],\n","    base_encoder_model.layers[1],\n","    ClassificationHed(6, 'softmax')\n","])\n","\n","for layer in encoder_non_linearity_model.layers[:-1]: \n","    layer.trainable = False\n","    \n","encoder_non_linearity_model.summary()"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-04-26T11:32:00.489179Z","iopub.status.busy":"2023-04-26T11:32:00.488804Z","iopub.status.idle":"2023-04-26T11:32:00.516928Z","shell.execute_reply":"2023-04-26T11:32:00.515969Z","shell.execute_reply.started":"2023-04-26T11:32:00.489146Z"},"trusted":true},"outputs":[],"source":["encoder_non_linearity_model.compile(loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"],\n","                                                     optimizer='adam')"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-04-26T11:32:12.439931Z","iopub.status.busy":"2023-04-26T11:32:12.439563Z","iopub.status.idle":"2023-04-26T11:35:42.680433Z","shell.execute_reply":"2023-04-26T11:35:42.679344Z","shell.execute_reply.started":"2023-04-26T11:32:12.439899Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/30\n","43/43 [==============================] - 16s 168ms/step - loss: 2.5646 - accuracy: 0.2204 - val_loss: 1.9056 - val_accuracy: 0.2055\n","Epoch 2/30\n","43/43 [==============================] - 5s 127ms/step - loss: 1.8255 - accuracy: 0.2785 - val_loss: 1.9274 - val_accuracy: 0.3014\n","Epoch 3/30\n","43/43 [==============================] - 6s 132ms/step - loss: 1.8591 - accuracy: 0.2770 - val_loss: 2.0465 - val_accuracy: 0.3151\n","Epoch 4/30\n","43/43 [==============================] - 5s 122ms/step - loss: 1.8100 - accuracy: 0.2985 - val_loss: 1.8834 - val_accuracy: 0.2568\n","Epoch 5/30\n","43/43 [==============================] - 5s 122ms/step - loss: 1.8342 - accuracy: 0.2941 - val_loss: 2.0320 - val_accuracy: 0.3390\n","Epoch 6/30\n","43/43 [==============================] - 5s 124ms/step - loss: 1.8390 - accuracy: 0.2974 - val_loss: 1.7780 - val_accuracy: 0.3425\n","Epoch 7/30\n","43/43 [==============================] - 5s 124ms/step - loss: 1.8554 - accuracy: 0.3185 - val_loss: 1.7912 - val_accuracy: 0.3185\n","Epoch 8/30\n","43/43 [==============================] - 5s 123ms/step - loss: 1.7311 - accuracy: 0.3400 - val_loss: 1.9189 - val_accuracy: 0.3425\n","Epoch 9/30\n","43/43 [==============================] - 5s 121ms/step - loss: 1.7425 - accuracy: 0.3363 - val_loss: 1.7207 - val_accuracy: 0.3630\n","Epoch 10/30\n","43/43 [==============================] - 5s 123ms/step - loss: 1.6933 - accuracy: 0.3526 - val_loss: 1.7777 - val_accuracy: 0.3390\n","Epoch 11/30\n","43/43 [==============================] - 5s 121ms/step - loss: 1.6985 - accuracy: 0.3637 - val_loss: 1.7187 - val_accuracy: 0.3288\n","Epoch 12/30\n","43/43 [==============================] - 5s 124ms/step - loss: 1.6912 - accuracy: 0.3556 - val_loss: 1.7915 - val_accuracy: 0.3459\n","Epoch 13/30\n","43/43 [==============================] - 5s 125ms/step - loss: 1.5787 - accuracy: 0.3893 - val_loss: 1.7181 - val_accuracy: 0.3288\n","Epoch 14/30\n","43/43 [==============================] - 5s 121ms/step - loss: 1.5852 - accuracy: 0.3919 - val_loss: 1.8497 - val_accuracy: 0.3527\n","Epoch 15/30\n","43/43 [==============================] - 5s 121ms/step - loss: 1.9129 - accuracy: 0.3489 - val_loss: 1.8331 - val_accuracy: 0.3390\n","Epoch 16/30\n","43/43 [==============================] - 5s 124ms/step - loss: 1.6678 - accuracy: 0.3767 - val_loss: 1.6020 - val_accuracy: 0.3801\n","Epoch 17/30\n","43/43 [==============================] - 5s 121ms/step - loss: 1.5524 - accuracy: 0.4252 - val_loss: 2.0221 - val_accuracy: 0.2397\n","Epoch 18/30\n","43/43 [==============================] - 5s 122ms/step - loss: 1.6409 - accuracy: 0.3785 - val_loss: 1.6974 - val_accuracy: 0.4144\n","Epoch 19/30\n","43/43 [==============================] - 5s 128ms/step - loss: 1.4901 - accuracy: 0.4285 - val_loss: 1.7063 - val_accuracy: 0.3390\n","Epoch 20/30\n","43/43 [==============================] - 5s 125ms/step - loss: 1.5165 - accuracy: 0.4356 - val_loss: 1.5417 - val_accuracy: 0.4384\n","Epoch 21/30\n","43/43 [==============================] - 5s 122ms/step - loss: 1.4136 - accuracy: 0.4700 - val_loss: 1.7524 - val_accuracy: 0.3048\n","Epoch 22/30\n","43/43 [==============================] - 5s 123ms/step - loss: 1.4649 - accuracy: 0.4570 - val_loss: 1.5164 - val_accuracy: 0.4212\n","Epoch 23/30\n","43/43 [==============================] - 5s 124ms/step - loss: 1.3912 - accuracy: 0.4785 - val_loss: 1.7265 - val_accuracy: 0.3562\n","Epoch 24/30\n","43/43 [==============================] - 5s 122ms/step - loss: 1.4873 - accuracy: 0.4485 - val_loss: 2.2811 - val_accuracy: 0.2603\n","Epoch 25/30\n","43/43 [==============================] - 5s 124ms/step - loss: 1.5383 - accuracy: 0.4367 - val_loss: 1.6414 - val_accuracy: 0.4349\n","Epoch 26/30\n","43/43 [==============================] - 5s 123ms/step - loss: 1.4606 - accuracy: 0.4685 - val_loss: 1.8634 - val_accuracy: 0.3322\n","Epoch 27/30\n","43/43 [==============================] - 5s 122ms/step - loss: 1.3948 - accuracy: 0.4837 - val_loss: 1.6913 - val_accuracy: 0.3733\n","Epoch 28/30\n","43/43 [==============================] - 5s 124ms/step - loss: 1.3837 - accuracy: 0.4822 - val_loss: 1.7643 - val_accuracy: 0.3664\n","Epoch 29/30\n","43/43 [==============================] - 5s 122ms/step - loss: 1.4802 - accuracy: 0.4574 - val_loss: 1.8431 - val_accuracy: 0.3459\n","Epoch 30/30\n","43/43 [==============================] - 5s 124ms/step - loss: 1.4173 - accuracy: 0.4752 - val_loss: 1.4353 - val_accuracy: 0.4623\n"]}],"source":["early_stopping = tf.keras.callbacks.EarlyStopping(\n","                                    monitor='val_loss',\n","                                    patience=5,\n","                                    verbose=0,\n","                                    mode='auto',\n","                                    baseline=None,\n","                                    restore_best_weights=True,\n","                                )\n","history = encoder_non_linearity_model.fit(train_X, train_y, batch_size=64, epochs=30, validation_data=(val_X, val_y))"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-04-26T11:39:45.889040Z","iopub.status.busy":"2023-04-26T11:39:45.888448Z","iopub.status.idle":"2023-04-26T11:39:46.375427Z","shell.execute_reply":"2023-04-26T11:39:46.374435Z","shell.execute_reply.started":"2023-04-26T11:39:45.888992Z"},"trusted":true},"outputs":[],"source":["save_loss_plot(\"loss_nonlinearity_simclr_eval.png\", history)\n","save_acc_plot(\"acc_nonlinearity_simclr_eval.png\", history)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
