{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/mf1024/ImageNet-Datasets-Downloader.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport requests\nimport argparse\nimport json\nimport time\nimport logging\nimport csv\n\nfrom multiprocessing import Pool, Process, Value, Lock\nfrom requests.exceptions import ConnectionError, ReadTimeout, TooManyRedirects, MissingSchema, InvalidURL\n\ndebug = False\nimages_per_class = 1000\nuse_class_list = True\nclass_list = [\"n02958343\",  'n02503517', 'n01323068', \"n02129165\", \n                                          \"n02691156\", \"n03793489\"]\nscrape_only_flickr = True\nnumber_of_classes = 10\nmultiprocessing_workers = 8\n\nIMAGENET_API_WNID_TO_URLS = lambda wnid: f'http://www.image-net.org/api/imagenet.synset.geturls?wnid={wnid}'\n\ncurrent_folder = 'ImageNet-Datasets-Downloader/'\n\nclass_info_json_filename = 'imagenet_class_info.json'\nclass_info_json_filepath = os.path.join(current_folder, class_info_json_filename)\n\nclass_info_dict = dict()\n\nwith open(class_info_json_filepath) as class_info_json_f:\n    class_info_dict = json.load(class_info_json_f)\n\nclasses_to_scrape = []\n\nif use_class_list == True:\n   for item in class_list:\n       classes_to_scrape.append(item)\n       if item not in class_info_dict:\n           logging.error(f'Class {item} not found in ImageNete')\n           exit()\n\nelif use_class_list == False:\n    potential_class_pool = []\n    for key, val in class_info_dict.items():\n\n        if scrape_only_flickr:\n            if int(val['flickr_img_url_count']) * 0.9 > images_per_class:\n                potential_class_pool.append(key)\n        else:\n            if int(val['img_url_count']) * 0.8 > images_per_class:\n                potential_class_pool.append(key)\n\n    if (len(potential_class_pool) < number_of_classes):\n        logging.error(f\"With {images_per_class} images per class there are {len(potential_class_pool)} to choose from.\")\n        logging.error(f\"Decrease number of classes or decrease images per class.\")\n        exit()\n\n    picked_classes_idxes = np.random.choice(len(potential_class_pool), number_of_classes, replace = False)\n\n    for idx in picked_classes_idxes:\n        classes_to_scrape.append(potential_class_pool[idx])\n\n\nprint(\"Picked the following clases:\")\nprint([ class_info_dict[class_wnid]['class_name'] for class_wnid in classes_to_scrape ])\n\nimagenet_images_folder = os.path.join(\"simclr_data\", 'imagenet_images')\nif not os.path.isdir(imagenet_images_folder):\n    os.mkdir(imagenet_images_folder)\n\n\nscraping_stats = dict(\n    all=dict(\n        tried=0,\n        success=0,\n        time_spent=0,\n    ),\n    is_flickr=dict(\n        tried=0,\n        success=0,\n        time_spent=0,\n    ),\n    not_flickr=dict(\n        tried=0,\n        success=0,\n        time_spent=0,\n    )\n)\n\ndef add_debug_csv_row(row):\n    with open('stats.csv', \"a\") as csv_f:\n        csv_writer = csv.writer(csv_f, delimiter=\",\")\n        csv_writer.writerow(row)\n\nclass MultiStats():\n    def __init__(self):\n\n        self.lock = Lock()\n\n        self.stats = dict(\n            all=dict(\n                tried=Value('d', 0),\n                success=Value('d',0),\n                time_spent=Value('d',0),\n            ),\n            is_flickr=dict(\n                tried=Value('d', 0),\n                success=Value('d',0),\n                time_spent=Value('d',0),\n            ),\n            not_flickr=dict(\n                tried=Value('d', 0),\n                success=Value('d', 0),\n                time_spent=Value('d', 0),\n            )\n        )\n    def inc(self, cls, stat, val):\n        with self.lock:\n            self.stats[cls][stat].value += val\n\n    def get(self, cls, stat):\n        with self.lock:\n            ret = self.stats[cls][stat].value\n        return ret\n\nmulti_stats = MultiStats()\n\n\nif False:\n    row = [\n        \"all_tried\",\n        \"all_success\",\n        \"all_time_spent\",\n        \"is_flickr_tried\",\n        \"is_flickr_success\",\n        \"is_flickr_time_spent\",\n        \"not_flickr_tried\",\n        \"not_flickr_success\",\n        \"not_flickr_time_spent\"\n    ]\n    add_debug_csv_row(row)\n\ndef add_stats_to_debug_csv():\n    row = [\n        multi_stats.get('all', 'tried'),\n        multi_stats.get('all', 'success'),\n        multi_stats.get('all', 'time_spent'),\n        multi_stats.get('is_flickr', 'tried'),\n        multi_stats.get('is_flickr', 'success'),\n        multi_stats.get('is_flickr', 'time_spent'),\n        multi_stats.get('not_flickr', 'tried'),\n        multi_stats.get('not_flickr', 'success'),\n        multi_stats.get('not_flickr', 'time_spent'),\n    ]\n    add_debug_csv_row(row)\n\ndef print_stats(cls, print_func):\n\n    actual_all_time_spent = time.time() - scraping_t_start.value\n    processes_all_time_spent = multi_stats.get('all', 'time_spent')\n\n    if processes_all_time_spent == 0:\n        actual_processes_ratio = 1.0\n    else:\n        actual_processes_ratio = actual_all_time_spent / processes_all_time_spent\n\n    #print(f\"actual all time: {actual_all_time_spent} proc all time {processes_all_time_spent}\")\n\n    print_func(f'STATS For class {cls}:')\n    print_func(f' tried {multi_stats.get(cls, \"tried\")} urls with'\n               f' {multi_stats.get(cls, \"success\")} successes')\n\n    if multi_stats.get(cls, \"tried\") > 0:\n        print_func(f'{100.0 * multi_stats.get(cls, \"success\")/multi_stats.get(cls, \"tried\")}% success rate for {cls} urls ')\n    if multi_stats.get(cls, \"success\") > 0:\n        print_func(f'{multi_stats.get(cls,\"time_spent\") * actual_processes_ratio / multi_stats.get(cls,\"success\")} seconds spent per {cls} succesful image download')\n\n\n\nlock = Lock()\nurl_tries = Value('d', 0)\nscraping_t_start = Value('d', time.time())\nclass_folder = ''\nclass_images = Value('d', 0)\n\ndef get_image(img_url):\n\n    #print(f'Processing {img_url}')\n\n    #time.sleep(3)\n\n    if len(img_url) <= 1:\n        return\n\n\n    cls_imgs = 0\n    with lock:\n        cls_imgs = class_images.value\n\n    if cls_imgs >= images_per_class:\n        return\n\n    logging.debug(img_url)\n\n    cls = ''\n\n    if 'flickr' in img_url:\n        cls = 'is_flickr'\n    else:\n        cls = 'not_flickr'\n        if scrape_only_flickr:\n            return\n\n    t_start = time.time()\n\n    def finish(status):\n        t_spent = time.time() - t_start\n        multi_stats.inc(cls, 'time_spent', t_spent)\n        multi_stats.inc('all', 'time_spent', t_spent)\n\n        multi_stats.inc(cls,'tried', 1)\n        multi_stats.inc('all', 'tried', 1)\n\n        if status == 'success':\n            multi_stats.inc(cls,'success', 1)\n            multi_stats.inc('all', 'success', 1)\n\n        elif status == 'failure':\n            pass\n        else:\n            logging.error(f'No such status {status}!!')\n            exit()\n        return\n\n\n    with lock:\n        url_tries.value += 1\n        if url_tries.value % 250 == 0:\n            print(f'\\nScraping stats:')\n            print_stats('is_flickr', print)\n            print_stats('not_flickr', print)\n            print_stats('all', print)\n            if debug:\n                add_stats_to_debug_csv()\n\n    try:\n        img_resp = requests.get(img_url, timeout = 1)\n    except ConnectionError:\n        logging.debug(f\"Connection Error for url {img_url}\")\n        return finish('failure')\n    except ReadTimeout:\n        logging.debug(f\"Read Timeout for url {img_url}\")\n        return finish('failure')\n    except TooManyRedirects:\n        logging.debug(f\"Too many redirects {img_url}\")\n        return finish('failure')\n    except MissingSchema:\n        return finish('failure')\n    except InvalidURL:\n        return finish('failure')\n\n    if not 'content-type' in img_resp.headers:\n        return finish('failure')\n\n    if not 'image' in img_resp.headers['content-type']:\n        logging.debug(\"Not an image\")\n        return finish('failure')\n\n    if (len(img_resp.content) < 1000):\n        return finish('failure')\n\n    logging.debug(img_resp.headers['content-type'])\n    logging.debug(f'image size {len(img_resp.content)}')\n\n    img_name = img_url.split('/')[-1]\n    img_name = img_name.split(\"?\")[0]\n\n    if (len(img_name) <= 1):\n        return finish('failure')\n\n    img_file_path = os.path.join(class_folder, img_name)\n    logging.debug(f'Saving image in {img_file_path}')\n\n    with open(img_file_path, 'wb') as img_f:\n        img_f.write(img_resp.content)\n\n        with lock:\n            class_images.value += 1\n\n        logging.debug(f'Scraping stats')\n        print_stats('is_flickr', logging.debug)\n        print_stats('not_flickr', logging.debug)\n        print_stats('all', logging.debug)\n\n        return finish('success')\n\n\nfor class_wnid in classes_to_scrape:\n\n    class_name = class_info_dict[class_wnid][\"class_name\"]\n    print(f'Scraping images for class \\\"{class_name}\\\"')\n    url_urls = IMAGENET_API_WNID_TO_URLS(class_wnid)\n\n    time.sleep(0.05)\n    resp = requests.get(url_urls)\n\n    class_folder = os.path.join(imagenet_images_folder, class_name)\n    if not os.path.exists(class_folder):\n        os.mkdir(class_folder)\n\n    class_images.value = 0\n\n    urls = [url.decode('utf-8') for url in resp.content.splitlines()]\n\n    #for url in  urls:\n    #    get_image(url)\n\n    print(f\"Multiprocessing workers: {multiprocessing_workers}\")\n    with Pool(processes=multiprocessing_workers) as p:\n        p.map(get_image,urls)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-24T03:08:35.846000Z","iopub.execute_input":"2023-04-24T03:08:35.846415Z","iopub.status.idle":"2023-04-24T03:10:32.565816Z","shell.execute_reply.started":"2023-04-24T03:08:35.846375Z","shell.execute_reply":"2023-04-24T03:10:32.564450Z"},"trusted":true},"execution_count":216,"outputs":[{"name":"stdout","text":"Picked the following clases:\n['car', 'elephant', 'tiger cub', 'lion', 'airplane', 'mouse']\nScraping images for class \"car\"\nMultiprocessing workers: 8\n\nScraping stats:\nSTATS For class is_flickr:\n tried 242.0 urls with 202.0 successes\n83.47107438016529% success rate for is_flickr urls \n0.02288476311334289 seconds spent per is_flickr succesful image download\nSTATS For class not_flickr:\n tried 0.0 urls with 0.0 successes\nSTATS For class all:\n tried 242.0 urls with 202.0 successes\n83.47107438016529% success rate for all urls \n0.023212544988877704 seconds spent per all succesful image download\n\nScraping stats:\nSTATS For class is_flickr:\n tried 492.0 urls with 407.0 successes\n82.72357723577235% success rate for is_flickr urls \n0.020271365382428203 seconds spent per is_flickr succesful image download\nSTATS For class not_flickr:\n tried 0.0 urls with 0.0 successes\nSTATS For class all:\n tried 494.0 urls with 407.0 successes\n82.38866396761134% success rate for all urls \n0.020354603080843237 seconds spent per all succesful image download\n\nScraping stats:\nSTATS For class is_flickr:\n tried 742.0 urls with 616.0 successes\n82.90713324360699% success rate for is_flickr urls \n0.022595397938360132 seconds spent per is_flickr succesful image download\nSTATS For class not_flickr:\n tried 0.0 urls with 0.0 successes\nSTATS For class all:\n tried 743.0 urls with 616.0 successes\n82.90713324360699% success rate for all urls \n0.022610659723158004 seconds spent per all succesful image download\nScraping images for class \"elephant\"\nMultiprocessing workers: 8\n\nScraping stats:\nSTATS For class is_flickr:\n tried 992.0 urls with 810.0 successes\n81.65322580645162% success rate for is_flickr urls \n0.027982026559335214 seconds spent per is_flickr succesful image download\nSTATS For class not_flickr:\n tried 0.0 urls with 0.0 successes\nSTATS For class all:\n tried 993.0 urls with 810.0 successes\n81.57099697885197% success rate for all urls \n0.028047484233055586 seconds spent per all succesful image download\n\nScraping stats:\nSTATS For class is_flickr:\n tried 1243.0 urls with 1002.0 successes\n80.61142397425583% success rate for is_flickr urls \n0.0261859927114018 seconds spent per is_flickr succesful image download\nSTATS For class not_flickr:\n tried 0.0 urls with 0.0 successes\nSTATS For class all:\n tried 1243.0 urls with 1002.0 successes\n80.61142397425583% success rate for all urls \n0.026242201675673923 seconds spent per all succesful image download\n\nScraping stats:\nSTATS For class is_flickr:\n tried 1494.0 urls with 1200.0 successes\n80.32128514056225% success rate for is_flickr urls \n0.02491276418498383 seconds spent per is_flickr succesful image download\nSTATS For class not_flickr:\n tried 0.0 urls with 0.0 successes\nSTATS For class all:\n tried 1496.0 urls with 1200.0 successes\n80.21390374331551% success rate for all urls \n0.024941838184992474 seconds spent per all succesful image download\nScraping images for class \"tiger cub\"\nMultiprocessing workers: 8\n\nScraping stats:\nSTATS For class is_flickr:\n tried 1742.0 urls with 1394.0 successes\n80.02296211251435% success rate for is_flickr urls \n0.02686234218318288 seconds spent per is_flickr succesful image download\nSTATS For class not_flickr:\n tried 0.0 urls with 0.0 successes\nSTATS For class all:\n tried 1743.0 urls with 1394.0 successes\n79.97705106138841% success rate for all urls \n0.026898610540578835 seconds spent per all succesful image download\n\nScraping stats:\nSTATS For class is_flickr:\n tried 1993.0 urls with 1571.0 successes\n78.82589061716006% success rate for is_flickr urls \n0.02615854583339037 seconds spent per is_flickr succesful image download\nSTATS For class not_flickr:\n tried 0.0 urls with 0.0 successes\nSTATS For class all:\n tried 1994.0 urls with 1571.0 successes\n78.7863590772317% success rate for all urls \n0.026186282419644505 seconds spent per all succesful image download\n\nScraping stats:\nSTATS For class is_flickr:\n tried 2242.0 urls with 1765.0 successes\n78.72435325602142% success rate for is_flickr urls \n0.02571385899616706 seconds spent per is_flickr succesful image download\nSTATS For class not_flickr:\n tried 0.0 urls with 0.0 successes\nSTATS For class all:\n tried 2242.0 urls with 1765.0 successes\n78.72435325602142% success rate for all urls \n0.025734350836648483 seconds spent per all succesful image download\n\nScraping stats:\nSTATS For class is_flickr:\n tried 2492.0 urls with 1961.0 successes\n78.66024869634978% success rate for is_flickr urls \n0.027005092172076917 seconds spent per is_flickr succesful image download\nSTATS For class not_flickr:\n tried 0.0 urls with 0.0 successes\nSTATS For class all:\n tried 2493.0 urls with 1961.0 successes\n78.66024869634978% success rate for all urls \n0.027013953518709433 seconds spent per all succesful image download\nScraping images for class \"lion\"\nMultiprocessing workers: 8\n\nScraping stats:\nSTATS For class is_flickr:\n tried 2742.0 urls with 2151.0 successes\n78.44638949671773% success rate for is_flickr urls \n0.028402629645687655 seconds spent per is_flickr succesful image download\nSTATS For class not_flickr:\n tried 0.0 urls with 0.0 successes\nSTATS For class all:\n tried 2743.0 urls with 2151.0 successes\n78.41779074006563% success rate for all urls \n0.028436409047125438 seconds spent per all succesful image download\n\nScraping stats:\nSTATS For class is_flickr:\n tried 2992.0 urls with 2336.0 successes\n78.07486631016043% success rate for is_flickr urls \n0.027824344190016184 seconds spent per is_flickr succesful image download\nSTATS For class not_flickr:\n tried 0.0 urls with 0.0 successes\nSTATS For class all:\n tried 2992.0 urls with 2336.0 successes\n78.07486631016043% success rate for all urls \n0.027847695432297172 seconds spent per all succesful image download\n\nScraping stats:\nSTATS For class is_flickr:\n tried 3242.0 urls with 2533.0 successes\n78.13078346699568% success rate for is_flickr urls \n0.02709523578005207 seconds spent per is_flickr succesful image download\nSTATS For class not_flickr:\n tried 0.0 urls with 0.0 successes\nSTATS For class all:\n tried 3244.0 urls with 2533.0 successes\n78.0826140567201% success rate for all urls \n0.0271170774521564 seconds spent per all succesful image download\n\nScraping stats:\nSTATS For class is_flickr:\n tried 3492.0 urls with 2721.0 successes\n77.92096219931271% success rate for is_flickr urls \n0.027929192910690334 seconds spent per is_flickr succesful image download\nSTATS For class not_flickr:\n tried 0.0 urls with 0.0 successes\nSTATS For class all:\n tried 3492.0 urls with 2721.0 successes\n77.92096219931271% success rate for all urls \n0.027945323885911005 seconds spent per all succesful image download\n\nScraping stats:\nSTATS For class is_flickr:\n tried 3743.0 urls with 2910.0 successes\n77.74512423189955% success rate for is_flickr urls \n0.028775566877778044 seconds spent per is_flickr succesful image download\nSTATS For class not_flickr:\n tried 0.0 urls with 0.0 successes\nSTATS For class all:\n\n tried 3743.0 urls with 2910.0 successes77.74512423189955% success rate for all urls \n0.028788030843964148 seconds spent per all succesful image download\nScraping images for class \"airplane\"\nMultiprocessing workers: 8\n\nScraping stats:\nSTATS For class is_flickr:\n tried 3992.0 urls with 3097.0 successes\n77.58016032064128% success rate for is_flickr urls \n0.03023352636842909 seconds spent per is_flickr succesful image download\nSTATS For class not_flickr:\n tried 0.0 urls with 0.0 successes\nSTATS For class all:\n tried 3993.0 urls with 3097.0 successes\n77.52190237797247% success rate for all urls \n0.030270980174570146 seconds spent per all succesful image download\n\nScraping stats:\nSTATS For class is_flickr:\n tried 4242.0 urls with 3278.0 successes\n77.27487034417727% success rate for is_flickr urls \n0.029651911393980778 seconds spent per is_flickr succesful image download\nSTATS For class not_flickr:\n tried 0.0 urls with 0.0 successes\nSTATS For class all:\n tried 4243.0 urls with 3278.0 successes\n77.25665802498233% success rate for all urls \n0.029674277222015762 seconds spent per all succesful image download\nScraping images for class \"mouse\"\nMultiprocessing workers: 8\n\nScraping stats:\nSTATS For class is_flickr:\n tried 4494.0 urls with 3455.0 successes\n76.88028482421005% success rate for is_flickr urls \n0.02953463435777016 seconds spent per is_flickr succesful image download\nSTATS For class not_flickr:\n tried 0.0 urls with 0.0 successes\nSTATS For class all:\n tried 4494.0 urls with 3455.0 successes\n76.86318131256952% success rate for all urls \n0.02955921409509504 seconds spent per all succesful image download\n\nScraping stats:\nSTATS For class is_flickr:\n tried 4742.0 urls with 3639.0 successes\n76.73977224799663% success rate for is_flickr urls \n0.02902420401147317 seconds spent per is_flickr succesful image download\nSTATS For class not_flickr:\n tried 0.0 urls with 0.0 successes\nSTATS For class all:\n tried 4742.0 urls with 3639.0 successes\n76.73977224799663% success rate for all urls \n0.029038912387102572 seconds spent per all succesful image download\n\nScraping stats:\nSTATS For class is_flickr:\n tried 4993.0 urls with 3830.0 successes\n76.70739034648508% success rate for is_flickr urls \n0.028686022198231347 seconds spent per is_flickr succesful image download\nSTATS For class not_flickr:\n tried 0.0 urls with 0.0 successes\nSTATS For class all:\n tried 4993.0 urls with 3830.0 successes\n76.70739034648508% success rate for all urls \n0.028696677765709302 seconds spent per all succesful image download\n\nScraping stats:\nSTATS For class is_flickr:\n tried 5248.0 urls with 4019.0 successes\n76.58155487804878% success rate for is_flickr urls \n0.028750520940146122 seconds spent per is_flickr succesful image download\nSTATS For class not_flickr:\n tried 0.0 urls with 0.0 successes\nSTATS For class all:\n tried 5248.0 urls with 4019.0 successes\n76.58155487804878% success rate for all urls \n0.02875700451361359 seconds spent per all succesful image download\n","output_type":"stream"}]},{"cell_type":"code","source":"import os \n\ndata_dir = \"simclr_data/imagenet_images/\"\n\ndef rename_files(data_dir):\n    for direc in os.listdir(data_dir): \n        try: \n            for indx, file in enumerate(os.listdir(data_dir+direc)): \n                try: \n                    src_filename = data_dir + direc + \"/\" + file\n                    dst_filename = data_dir + direc + \"/\" + str(direc) + f\"_{indx}.jpg\"\n\n                    if indx >= 900: \n                        os.remove(src_filename) \n\n                    if str(direc)[0] != file[0] and indx <= 400: \n                        os.rename(src_filename, dst_filename)\n                        \n                except Exception as error:\n                    continue\n\n        except Exception as error:\n            return error \n                \nrename_files(data_dir)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T03:11:14.439709Z","iopub.execute_input":"2023-04-24T03:11:14.440741Z","iopub.status.idle":"2023-04-24T03:11:14.501143Z","shell.execute_reply.started":"2023-04-24T03:11:14.440694Z","shell.execute_reply":"2023-04-24T03:11:14.500087Z"},"trusted":true},"execution_count":217,"outputs":[]},{"cell_type":"code","source":"import shutil \nimport random\nimport numpy as np \n\ndef create_train_test_data(data_path, num_train, num_test, num_val): \n    directories = os.listdir(data_path)\n    if not os.path.exists(\"train\"):\n        os.mkdir(\"train\")\n        \n    if not os.path.exists(\"test\"):\n        os.mkdir(\"test\")\n        \n    if not os.path.exists(\"val\"):\n        os.mkdir(\"val\")\n    \n    for directory in directories: \n        try: \n            files_list = os.listdir(data_path+directory)\n            train_files = np.random.choice(files_list, num_train, replace=False)\n            test_files = [file for file in files_list if not file in train_files][: 50]\n            val_files = [file for file in files_list if (not file in train_files and not file in test_files)][: 50]\n            \n            for train_file in train_files:\n                src = data_path + directory + '/' + train_file\n                dst = \"train\" + \"/\" + train_file\n                shutil.copyfile(src, dst)\n\n            for test_file in test_files:\n                src = data_path + directory + '/' + test_file\n                dst = \"test\" + \"/\" + test_file\n                shutil.copyfile(src, dst)\n                \n            for val_file in val_files:\n                src = data_path + directory + '/' + val_file\n                dst = \"val\" + \"/\" + val_file\n                shutil.copyfile(src, dst)\n                \n        except Exception as error:\n            return error\n            ","metadata":{"execution":{"iopub.status.busy":"2023-04-24T03:24:10.435089Z","iopub.execute_input":"2023-04-24T03:24:10.436116Z","iopub.status.idle":"2023-04-24T03:24:10.448147Z","shell.execute_reply.started":"2023-04-24T03:24:10.436066Z","shell.execute_reply":"2023-04-24T03:24:10.446943Z"},"trusted":true},"execution_count":267,"outputs":[]},{"cell_type":"code","source":"create_train_test_data(data_dir, 340, 50, 50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_image_files = os.listdir('train')\ntest_image_files = os.listdir('test')\nval_image_file = os.listdir('val')","metadata":{"execution":{"iopub.status.busy":"2023-04-24T03:24:37.113714Z","iopub.execute_input":"2023-04-24T03:24:37.114041Z","iopub.status.idle":"2023-04-24T03:24:37.121591Z","shell.execute_reply.started":"2023-04-24T03:24:37.114010Z","shell.execute_reply":"2023-04-24T03:24:37.120562Z"},"trusted":true},"execution_count":273,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras \nimport tensorflow as tf \n\n\n# Image preprocessing utils\n@tf.function\ndef parse_images(image_path):\n    image_string = tf.io.read_file(image_path)\n    image = tf.image.decode_jpeg(image_string, channels=3)\n    image = tf.image.convert_image_dtype(image, tf.float32)\n    image = tf.image.resize(image, size=[224, 224])\n\n    return image\n\ndef create_tensorflow_dataset(data, batch_size):\n    tensorflow_data = tf.data.Dataset.from_tensor_slices(train_image_files)\n    tensorflow_data = (\n    tensorflow_data\n        .map(parse_images, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n        .shuffle(1024)\n        .batch(batch_size, drop_remainder=True)\n        .prefetch(tf.data.experimental.AUTOTUNE)\n    )\n    return tensorflow_data        ","metadata":{"execution":{"iopub.status.busy":"2023-04-24T03:06:00.156281Z","iopub.execute_input":"2023-04-24T03:06:00.157349Z","iopub.status.idle":"2023-04-24T03:06:00.165880Z","shell.execute_reply.started":"2023-04-24T03:06:00.157298Z","shell.execute_reply":"2023-04-24T03:06:00.164601Z"},"trusted":true},"execution_count":207,"outputs":[]},{"cell_type":"code","source":"train_ds = create_tensorflow_dataset(train_image_files, 32)\ntest_ds = create_tensorflow_dataset(test_image_files, 32)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T03:06:10.166131Z","iopub.execute_input":"2023-04-24T03:06:10.167567Z","iopub.status.idle":"2023-04-24T03:06:10.187803Z","shell.execute_reply.started":"2023-04-24T03:06:10.167518Z","shell.execute_reply":"2023-04-24T03:06:10.186637Z"},"trusted":true},"execution_count":209,"outputs":[]},{"cell_type":"code","source":"350 * 6","metadata":{"execution":{"iopub.status.busy":"2023-04-24T03:17:01.344801Z","iopub.execute_input":"2023-04-24T03:17:01.345828Z","iopub.status.idle":"2023-04-24T03:17:01.353591Z","shell.execute_reply.started":"2023-04-24T03:17:01.345785Z","shell.execute_reply":"2023-04-24T03:17:01.352391Z"},"trusted":true},"execution_count":235,"outputs":[{"execution_count":235,"output_type":"execute_result","data":{"text/plain":"2100"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}